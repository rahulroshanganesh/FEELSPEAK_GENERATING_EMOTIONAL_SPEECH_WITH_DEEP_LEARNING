{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358d7d7d",
   "metadata": {
    "id": "358d7d7d"
   },
   "source": [
    "# TEXT EMOTION DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616dbc07",
   "metadata": {
    "id": "616dbc07"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7ea18",
   "metadata": {
    "id": "09a7ea18"
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fdf46d",
   "metadata": {
    "id": "d2fdf46d"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/TEXT-EMOTION/emotion_dataset_raw.csv\")\n",
    "df = pd.read_csv(\"C:/Users/samga/OneDrive/Desktop/capstone/Text-Emotion-Detection/Text Emotion Detection/data/emotion_dataset_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4841dd0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4841dd0f",
    "outputId": "5726e605-b0ea-42a1-c6e0-a215b8fda3fc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral                                             Why ? \n",
       "1      joy    Sage Act upgrade on my to do list for tommorow.\n",
       "2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...\n",
       "3      joy   Such an eye ! The true hazel eye-and so brill...\n",
       "4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b224913",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b224913",
    "outputId": "b8317f68-8ae0-44d1-83c2-6fd21fb085f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         11045\n",
       "sadness      6722\n",
       "fear         5410\n",
       "anger        4297\n",
       "surprise     4062\n",
       "neutral      2254\n",
       "disgust       856\n",
       "shame         146\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55053732",
   "metadata": {
    "id": "55053732"
   },
   "outputs": [],
   "source": [
    "# sns.countplot(x='Emotion',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44cdbf",
   "metadata": {
    "id": "6e44cdbf"
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1175202",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1175202",
    "outputId": "468d8275-7447-4749-c595-09d436389022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neattext\n",
      "  Downloading neattext-0.1.3-py3-none-any.whl (114 kB)\n",
      "     ---------------------------------------- 0.0/114.7 kB ? eta -:--:--\n",
      "     ------------------------------- ------- 92.2/114.7 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 114.7/114.7 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: neattext\n",
      "Successfully installed neattext-0.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neattext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip3 install neattext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneattext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnfx\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Remove the user handles\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClean_Text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(nfx\u001b[38;5;241m.\u001b[39mremove_userhandles)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neattext'"
     ]
    }
   ],
   "source": [
    "!pip3 install neattext\n",
    "import neattext.functions as nfx\n",
    "\n",
    "# Remove the user handles\n",
    "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bff967",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bff967",
    "outputId": "d7ae9612-193a-4f49-ec39-a1f46cb28e22"
   },
   "outputs": [],
   "source": [
    "dir(nfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8f2f0",
   "metadata": {
    "id": "18b8f2f0"
   },
   "outputs": [],
   "source": [
    "# Remove the stopwords\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdaf676",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "ecdaf676",
    "outputId": "34943e72-2358-444b-f69a-14a9bed46727"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61757d",
   "metadata": {
    "id": "5a61757d"
   },
   "source": [
    "### Splitting data into input variables and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b12855",
   "metadata": {
    "id": "d9b12855"
   },
   "source": [
    "x: Features are the attributes and variables extracted from the dataset. These extracted features are used as inputs to the model during training.\n",
    "\n",
    "y: Labels are the output or the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2568bf5",
   "metadata": {
    "id": "d2568bf5"
   },
   "outputs": [],
   "source": [
    "x = df['Clean_Text']\n",
    "y = df['Emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be53a4f",
   "metadata": {
    "id": "0be53a4f"
   },
   "source": [
    "### Splitting data into train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153c41a",
   "metadata": {
    "id": "d153c41a"
   },
   "source": [
    "We need to split our dataset into a train set and test set. The model will learn from the train set. We will use the test set to evaluate the model performance and measure the modelâ€™s knowledge capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781e536",
   "metadata": {
    "id": "0781e536"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bk-HunoeO3jK",
   "metadata": {
    "id": "bk-HunoeO3jK"
   },
   "outputs": [],
   "source": [
    "x_numpy = x.values\n",
    "\n",
    "# Reshape the input data to 2D array if it's 1D\n",
    "x_reshaped = x_numpy.reshape(-1, 1)\n",
    "\n",
    "# Instantiate RandomOverSampler to balance the data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(x_reshaped, y)\n",
    "\n",
    "# Convert the resampled data back to pandas Series if needed\n",
    "x_resampled_series = pd.Series(X_resampled.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dl6FQHizff5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "Dl6FQHizff5d",
    "outputId": "211331f6-b181-41c8-9229-cc7e2b988671"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Emotion',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6TaH8UogU4iJ",
   "metadata": {
    "id": "6TaH8UogU4iJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_resampled_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mx_resampled_series\u001b[49m, y_resampled, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_resampled_series' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_resampled_series, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "YYQ2ZvvNQhaQ",
   "metadata": {
    "id": "YYQ2ZvvNQhaQ"
   },
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(steps=[\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94068470",
   "metadata": {
    "id": "94068470"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab70dcb",
   "metadata": {
    "id": "2ab70dcb"
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d3bb4f3",
   "metadata": {
    "id": "8d3bb4f3"
   },
   "outputs": [],
   "source": [
    "# pipe_lr = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression())])\n",
    "# pipe_lr.fit(X_train_resampled,y_train_resampled)\n",
    "# pipe_lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b6b506",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89b6b506",
    "outputId": "3b98578d-4c74-4d89-a20e-38ab19d566d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8613626075147125\n"
     ]
    }
   ],
   "source": [
    "pipe_lr.fit(X_train, y_train)\n",
    "accuracy = pipe_lr.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pU6Lq8OzenKx",
   "metadata": {
    "id": "pU6Lq8OzenKx"
   },
   "outputs": [],
   "source": [
    "emotion_attached_training_data = []\n",
    "# pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "for sentence in X_train:\n",
    "  # Clean the sentence\n",
    "  sentence = nfx.remove_userhandles(sentence)\n",
    "  sentence = nfx.remove_stopwords(sentence)\n",
    "\n",
    "  # Predict the emotion of the sentence\n",
    "  emotion = pipe_lr.predict([sentence])[0]\n",
    "\n",
    "  # Add the emotion to the sentence\n",
    "  emotion_attached_sentence = f\"{sentence} <{emotion}>\"\n",
    "  emotion_attached_training_data.append(emotion_attached_sentence)\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(emotion_attached_training_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df1.to_csv('emotion_attached_training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "T3wRHVIOXpsl",
   "metadata": {
    "id": "T3wRHVIOXpsl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46e9ce98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46e9ce98",
    "outputId": "d7068d29-9d9a-42cc-d040-b6d46534376f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.893843368039837\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = Pipeline(steps=[('cv',CountVectorizer()),('rf', RandomForestClassifier(n_estimators=100, random_state=42))])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "predictions = pipe_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "BIbvM6XfY3o3",
   "metadata": {
    "id": "BIbvM6XfY3o3"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "E-vJx-KcY7Pg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-vJx-KcY7Pg",
    "outputId": "55ac8f84-183f-4241-963c-8d13d4bdc79f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8793005885015844\n"
     ]
    }
   ],
   "source": [
    "pipe_svm = Pipeline(steps=[\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('svm', SVC(kernel='linear', random_state=42))  # SVM with linear kernel\n",
    "])\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "predictions = pipe_svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "zulmSHg3aKy8",
   "metadata": {
    "id": "zulmSHg3aKy8"
   },
   "outputs": [],
   "source": [
    "# emotion_attached_training_data = []\n",
    "# # pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# for sentence in X_train:\n",
    "#   # Clean the sentence\n",
    "#   sentence = nfx.remove_userhandles(sentence)\n",
    "#   sentence = nfx.remove_stopwords(sentence)\n",
    "\n",
    "#   # Predict the emotion of the sentence\n",
    "#   emotion = pipe_lr.predict([sentence])[0]\n",
    "\n",
    "#   # Add the emotion to the sentence\n",
    "#   emotion_attached_sentence = f\"{sentence} <{emotion}>\"\n",
    "#   emotion_attached_training_data.append(emotion_attached_sentence)\n",
    "\n",
    "\n",
    "# df1 = pd.DataFrame(emotion_attached_training_data)\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# df1.to_csv('emotion_attached_training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac497a",
   "metadata": {
    "id": "30ac497a"
   },
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed05d1fc",
   "metadata": {
    "id": "ed05d1fc"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "pipeline_file = open(\"text_emotion_balanced_dataset.pkl\",\"wb\")\n",
    "joblib.dump(pipe_lr,pipeline_file)\n",
    "pipeline_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b4a21ff",
   "metadata": {
    "id": "5b4a21ff"
   },
   "outputs": [],
   "source": [
    "# def attach_emotions(text):\n",
    "#   # Clean the text\n",
    "#   text = nfx.remove_userhandles(text)\n",
    "#   text = nfx.remove_stopwords(text)\n",
    "\n",
    "#   # Predict the emotion of the text\n",
    "#   emotion = pipe_lr.predict([text])[0]\n",
    "\n",
    "#   # Add the emotion to the text\n",
    "#   text = f\"{text} ({emotion})\"\n",
    "\n",
    "#   return text\n",
    "\n",
    "# # Example usage\n",
    "# text = \"I am so happy today!\"\n",
    "# emotion_attached_text = attach_emotions(text)\n",
    "# print(emotion_attached_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "g9J5kLnTIJEz",
   "metadata": {
    "id": "g9J5kLnTIJEz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "EXxmPRKHINGU",
   "metadata": {
    "id": "EXxmPRKHINGU"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vfl9Z3BEINgH",
   "metadata": {
    "id": "vfl9Z3BEINgH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
